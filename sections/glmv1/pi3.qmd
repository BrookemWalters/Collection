---
title: "inventory prediction"
format: 
  html:
    code-fold: true
---

```{r include=FALSE}
setwd("~/gvsu/summer 23/stat 631/Collection/sections/glmv1")

if (!require("pacman")) {
  install.packages("pacman")
  library("pacman")
}
#Import Libraries

# Use p_load() to install (if necessary) and load  packages
pacman::p_load(tidyverse,
               tidymodels,
               leaps,
               corrplot,
               MMWRweek,
               broom,
               poissonreg) # parsnips for poisson
```

```{r}
# import data
sai <-  read.csv("inventory.csv")
```

DRAFT DRAFT OUTLINE

## Description of Data:
The initial inventory dataset contains 26,352 items sold over the course of 54 weeks
(0-53)

[insert histogram of items sold]


## Limitations
12 months of data is not great for this preserves the temporal order.
A more robost dataset to work on would include a couple years of data

## Statistical Summary:

Provide a statistical summary of the variables. This includes measures of central tendency (mean, median, mode), dispersion (range, standard deviation, variance), and distribution properties (skewness, kurtosis). This could be supplemented with summary tables and histograms.

\[insert\]

## Visual Exploration:

Use visualizations to give an overview of the data. Histograms, box plots, scatter plots, or correlation heatmaps can be used to show relationships and trends within the data..

\[insert\]

## Initial Insights:

Start by providing a comprehensive summary of the dataset. This includes source information, timeframe, and the main purpose for collection. Each variable should be properly named and described. This could be presented in the form of a data dictionary.

\[insert\]

## Feature engineering
I needed to create a few more variables help with the predictions:

(link to data dictionary)

-   totals for each item over the year
-   which items are best selling? top ten items based on volume
-   convert weeks to dates so we can extract the month
-   lag period for seasonality
-   rolling mean

```{r}
# total yearly sales for each item
inventory_sum <- sai %>%
  group_by(item_no) %>%
  summarise(year_total = sum(sold), .groups = "drop")

sai <- left_join(sai, inventory_sum, by = c("item_no"))

###
# calculate the top 10% threshold
top_10_threshold <- quantile(sai$year_total, 0.9)

# dummy variable for bestsellers 1= yes 0 = no
sai <- sai %>%
  mutate(best_seller = ifelse(year_total >= top_10_threshold, 1, 0))

## figure out month an year for data, assuming the data is from  2022
# week 0: December 27, 2021 - January 2, 2022
# week 52: December 19, 2022 - December 25, 2022
# week 53: December 26, 2022 - January 1, 2023

sai$year <- 2022

sai <- sai %>%
  mutate(calendar_week = ifelse(week == 0, 52, ifelse(week == 53, 1, week)),
         calendar_year = ifelse(week == 0, year - 1, ifelse(week == 53, year + 1, year)))

# Now use calendar_year and calendar_week in the MMWRweek2Date function
sai$date <- MMWRweek2Date(sai$calendar_year, sai$calendar_week)



# find the year the week ends in, so we can figure out months
sai <- sai %>%
  mutate(wk_ending_year = ifelse(week %in% c(0, 53), year + 1, year),
         week = ifelse(week == 53, 1, week))



# create teh data and extract the month
# wanted month to be quantitative to reduce model complexity

sai$date <- MMWRweek2Date(sai$wk_ending_year, sai$calendar_week)
sai$month <- month(sai$date, label = TRUE)
sai$month <- month(sai$date)


# create lag periods
# https://www.youtube.com/watch?v=Kn3llTjYS5E

sai <- sai %>%
  mutate(lag1 = lag(sold, 1),
         lag2 = lag(sold, 2))

# https://www.rdocumentation.org/packages/zoo/versions/1.8-12/topics/rollmean
sai <- sai %>%
  group_by(item_no) %>%
  mutate(rolling_4wk_avg = zoo::rollmean(sold, k = 4, fill = NA, align = "right")) %>%
  ungroup()
```

```{r}

head(sai)
colnames(sai)
# validate data
write.csv(sai, "FEinventory.csv")
```

```{r}
a5i <-  sai %>% 
  filter(item_no == 'A510004') %>% 
  dplyr::select(
    week,
    month,
    lag1,
    lag2,
    rolling_4wk_avg,
    sold) #not sure why i had to include the dplyr package


```

create a model based on the best selling item, inventory with more items sold are more predcitable. 

## Model Selection
find the best model using stepwise selection find the 2 best methods for every size predictors

- define generalized linear regression and why I chose this for the model
- i removed the best sellers because all of the items were best sellers

```{r message=FALSE, warning=FALSE}

# https://youtu.be/IScjygOnO0w
set.seed(3746)
# forward Stepwise Selection
# nvmax = 8 specifies the maximum number of predictors to incorporate in the model.
a5i_mod <- regsubsets(sold ~  .,
                       data = a5i, nbest = 2, method = "exhaustive")
a5i_mod_summary_mx <- with(summary(a5i_mod), data.frame(rsq,adjr2, cp, rss, outmat))

a5i_mod_summary_mx$predictors_cnt <- c(1,1,2,2,3,3,4,4,5) # for graphing
a5i_mod_summary_mx$model <- c('a','b','a','b','a','b','a','b','a') # for graphing
a5i_mod_summary_mx$modeltype <-  "lrm"

# insert the num_predictors column to a5i_mod_summary_mx
a5i_mod_summary_mx 

```

### model evaluation

```{r}
a5i_mod_summary_mx %>% 
  pivot_longer(c(adjr2, cp), names_to = "metric", values_to = "value") %>%
  ggplot(aes(x = predictors_cnt, y = value, color = model)) +
  geom_line(show.legend = F) +
  geom_point() +
  facet_wrap(~metric, scales = "free") +
  scale_x_continuous(breaks = 1:5)
```

# show the models in a table

```{r}
# create the table
```


explain why this is the best one
what do each of these things tell me?

-   rsq -\> highest r squared, explains the variability in the model
-   adjr2 - \> highest
-   cp -\> smallest
-   rss -\> smallest

having trouble choosing, i spent a lot of time making my variables so lets look at AIC several models what is AIC? Lower AIC values indicate a better-fit model, and a model with a delta-AIC (the difference between the two AIC values being compared) of more than -2 is considered significantly better than the model it is being compared to

find the coefficients and (Akaike Information Criterion) AIC

```{r}
mod_compare <-  a5i_mod_summary_mx %>% 
  filter(model == "a",
         predictors_cnt >2) %>% 
  dplyr:: select(predictors_cnt,
          rsq,
          adjr2,
          cp,
          rss)


# best adjusted r squared 5 predictors 
mod5 <-  lm(sold~ month + week + lag1 + lag2 + rolling_4wk_avg , data = a5i)
mod5_aic <- AIC(mod5)


# mix of cp and adjusted r squared model a
mod4 <-  lm(sold~ month + lag1 + lag2 + rolling_4wk_avg , data = a5i)
mod4_aic <- AIC(mod4)

# best cp model a
mod3 <-  lm(sold~ lag1 + lag2 + rolling_4wk_avg , data = a5i)
mod3_aic <- AIC(mod3)


mod_compare$AIC <-  c(mod3_aic,mod4_aic, mod5_aic )
mod_compare
```

https://emilhvitfeldt.github.io/ISLR-tidymodels-labs/04-classification.html

```{r}
train_index <- 1:(nrow(sai) - 12)
sai_train <- sai[train_index, ]
sai_test <- sai[-train_index, ]
```


```{r}
pois_spec <- poisson_reg() %>% 
  set_mode("regression") %>% 
  set_engine("glm")
```


```{r}
pois_rec_spec <- recipe(
  sold~ lag1 + lag2 + rolling_4wk_avg + best_seller ,
  data = sai,
) %>% 
  step_dummy(all_nominal_predictors())
```


use a group of items 

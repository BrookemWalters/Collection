{
  "hash": "c54054b62e90bde190bd7ac988465ef8",
  "result": {
    "markdown": "---\ntitle: \"inventory prediction\"\nformat: \n  html:\n    code-fold: true\n---\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# import data\nsai <-  read.csv(\"inventory.csv\")\n```\n:::\n\n\nDRAFT DRAFT OUTLINE\n\n## Description of Data:\nThe initial inventory dataset contains 488 items sold over the course of 54 weeks\n(0-53)\n\n[insert histogram of items sold]\n\n\n## Limitations\n12 months of data is not great for this preserves the temporal order.\nA more robost dataset to work on would include a couple years of data\n\n## Statistical Summary:\n\nProvide a statistical summary of the variables. This includes measures of central tendency (mean, median, mode), dispersion (range, standard deviation, variance), and distribution properties (skewness, kurtosis). This could be supplemented with summary tables and histograms.\n\n\\[insert\\]\n\n## Visual Exploration:\n\nUse visualizations to give an overview of the data. Histograms, box plots, scatter plots, or correlation heatmaps can be used to show relationships and trends within the data..\n\n\\[insert\\]\n\n## Initial Insights:\n\nStart by providing a comprehensive summary of the dataset. This includes source information, timeframe, and the main purpose for collection. Each variable should be properly named and described. This could be presented in the form of a data dictionary.\n\n\\[insert\\]\n\n## Feature engineering\nI needed to create a few more variables help with the predictions:\n\n(link to data dictionary)\n\n-   totals for each item over the year\n-   which items are best selling? top ten items based on volume\n-   convert weeks to dates so we can extract the month\n-   lag period for seasonality\n-   rolling mean\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# total yearly sales for each item\ninventory_sum <- sai %>%\n  group_by(item_no) %>%\n  summarise(year_total = sum(sold), .groups = \"drop\")\n\nsai <- left_join(sai, inventory_sum, by = c(\"item_no\"))\n\n###\n# calculate the top 10% threshold\ntop_10_threshold <- quantile(sai$year_total, 0.9)\n\n# dummy variable for bestsellers 1= yes 0 = no\nsai <- sai %>%\n  mutate(best_seller = ifelse(year_total >= top_10_threshold, 1, 0))\n\n## figure out month an year for data, assuming the data is from  2022\n# week 0: December 27, 2021 - January 2, 2022\n# week 52: December 19, 2022 - December 25, 2022\n# week 53: December 26, 2022 - January 1, 2023\n\nsai$year <- 2022\n\nsai <- sai %>%\n  mutate(calendar_week = ifelse(week == 0, 52, ifelse(week == 53, 1, week)),\n         calendar_year = ifelse(week == 0, year - 1, ifelse(week == 53, year + 1, year)))\n\n# Now use calendar_year and calendar_week in the MMWRweek2Date function\nsai$date <- MMWRweek2Date(sai$calendar_year, sai$calendar_week)\n\n\n\n# find the year the week ends in, so we can figure out months\nsai <- sai %>%\n  mutate(wk_ending_year = ifelse(week %in% c(0, 53), year + 1, year),\n         week = ifelse(week == 53, 1, week))\n\n\n\n# create teh data and extract the month\n# wanted month to be quantitative to reduce model complexity\n\nsai$date <- MMWRweek2Date(sai$wk_ending_year, sai$calendar_week)\nsai$month <- month(sai$date, label = TRUE)\nsai$month <- month(sai$date)\n\n\n# create lag periods\n# https://www.youtube.com/watch?v=Kn3llTjYS5E\n\nsai <- sai %>%\n  mutate(lag1 = lag(sold, 1),\n         lag2 = lag(sold, 2))\n\n# https://www.rdocumentation.org/packages/zoo/versions/1.8-12/topics/rollmean\nsai <- sai %>%\n  group_by(item_no) %>%\n  mutate(rolling_4wk_avg = zoo::rollmean(sold, k = 4, fill = NA, align = \"right\")) %>%\n  ungroup()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(sai)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 14\n  item_no  week  sold year_total best_seller  year calendar_week calendar_year\n  <chr>   <dbl> <int>      <int>       <dbl> <dbl>         <dbl>         <dbl>\n1 020-307     0     0        880           0  2022            52          2021\n2 020-307     1    80        880           0  2022             1          2022\n3 020-307     2     0        880           0  2022             2          2022\n4 020-307     3     0        880           0  2022             3          2022\n5 020-307     4     0        880           0  2022             4          2022\n6 020-307     5     0        880           0  2022             5          2022\n# ℹ 6 more variables: date <date>, wk_ending_year <dbl>, month <dbl>,\n#   lag1 <int>, lag2 <int>, rolling_4wk_avg <dbl>\n```\n:::\n\n```{.r .cell-code}\ncolnames(sai)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"item_no\"         \"week\"            \"sold\"            \"year_total\"     \n [5] \"best_seller\"     \"year\"            \"calendar_week\"   \"calendar_year\"  \n [9] \"date\"            \"wk_ending_year\"  \"month\"           \"lag1\"           \n[13] \"lag2\"            \"rolling_4wk_avg\"\n```\n:::\n\n```{.r .cell-code}\n# validate data\nwrite.csv(sai, \"FEinventory.csv\")\n```\n:::\n\n\n# two model predictions update this to select random item numbers 75%\n# second model will use week 0 to predict week 54 vs 25%\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1985)\nitems_sample_list <-  unique(sai$item_no) %>% \n  sample(366)\n# 75% of the data\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# splitting the inventory by item type to keep the temporal order\n\nis_train <-  sai %>% \n  filter(item_no %in% items_sample_list) %>% \n  dplyr::select(\n    item_no,\n    week,\n    month,\n    lag1,\n    lag2,\n    rolling_4wk_avg,\n    best_seller, \n    sold) #not sure why i had to include the dplyr package\n\n\nis_test<-  sai %>% \n  filter(!(item_no %in% items_sample_list)) %>% \n  dplyr::select(\n    item_no,\n    week,\n    month,\n    lag1,\n    lag2,\n    rolling_4wk_avg,\n    best_seller, \n    sold) #not sure why i had to include the dplyr package\n```\n:::\n\n\ncreate a model based on the best selling item, inventory with more items sold are more predcitable. \n\n## Model Selection\nfind the best model using stepwise selection find the 2 best methods for every size predictors\n\n- define generalized linear regression and why I chose this for the model\n- i removed the best sellers because all of the items were best sellers\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# https://youtu.be/IScjygOnO0w\n# forward Stepwise Selection\n# nvmax = 8 specifies the maximum number of predictors to incorporate in the model.\nis_mod <- regsubsets(sold ~ week + month + lag1 + lag2 + rolling_4wk_avg + best_seller,\n                       data = is_test, nbest = 2, method = \"exhaustive\")\nis_mod_summary_mx <- with(summary(is_mod), data.frame(rsq,adjr2, cp, rss, outmat))\n\nis_mod_summary_mx$predictors <- c(1,1,2,2,3,3,4,4,5,5,6) # for graphing\nis_mod_summary_mx$model <- c('a','b','a','b','a','b','a','b','a', 'b', 'a') # for graphing\n\n# insert the num_predictors column to a5i_mod_summary_mx\nis_mod_summary_mx \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                rsq      adjr2          cp       rss week month lag1 lag2\n1  ( 1 ) 0.35517493 0.35507126 3641.238692 347410480                     \n1  ( 2 ) 0.07253195 0.07238283 7962.790093 499689200                     \n2  ( 1 ) 0.47178311 0.47161324 1860.324363 284585840                    *\n2  ( 2 ) 0.40971495 0.40952512 2809.333361 318026117               *     \n3  ( 1 ) 0.59311658 0.59292027    7.161336 219215369               *    *\n3  ( 2 ) 0.47179023 0.47153538 1862.215571 284582007          *         *\n4  ( 1 ) 0.59312292 0.59286113    9.064396 219211953          *    *    *\n4  ( 2 ) 0.59311764 0.59285586    9.145038 219214795               *    *\n5  ( 1 ) 0.59351846 0.59319149    5.016718 218998851    *     *    *    *\n5  ( 2 ) 0.59312400 0.59279672   11.047895 219211372          *    *    *\n6  ( 1 ) 0.59351955 0.59312713    7.000000 218998262    *     *    *    *\n         rolling_4wk_avg best_seller predictors model\n1  ( 1 )               *                      1     a\n1  ( 2 )                           *          1     b\n2  ( 1 )               *                      2     a\n2  ( 2 )               *                      2     b\n3  ( 1 )               *                      3     a\n3  ( 2 )               *                      3     b\n4  ( 1 )               *                      4     a\n4  ( 2 )               *           *          4     b\n5  ( 1 )               *                      5     a\n5  ( 2 )               *           *          5     b\n6  ( 1 )               *           *          6     a\n```\n:::\n:::\n\n\n### model evaluation\n\n\n::: {.cell}\n\n```{.r .cell-code}\nis_mod_summary_mx %>% \n  pivot_longer(c(adjr2, cp), names_to = \"metric\", values_to = \"value\") %>%\n  ggplot(aes(x = predictors, y = value, color = model)) +\n  geom_line(show.legend = F) +\n  geom_point() +\n  facet_wrap(~metric, scales = \"free\") +\n  scale_x_continuous(breaks = 1:6)\n```\n\n::: {.cell-output-display}\n![](pi_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n# show the models in a table\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create the table\n```\n:::\n\n\n\nexplain why this is the best one\nwhat do each of these things tell me?\n\n-   rsq -\\> highest r squared, explains the variability in the model\n\n\n\n-   adjr2 - \\> highest\n-   cp -\\> smallest\n-   rss -\\> smallest\n\nhaving trouble choosing, i spent a lot of time making my variables so lets look at AIC several models what is AIC? Lower AIC values indicate a better-fit model, and a model with a delta-AIC (the difference between the two AIC values being compared) of more than -2 is considered significantly better than the model it is being compared to\n\nfind the coefficients and (Akaike Information Criterion) AIC\nMultiple linear regression\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#https://emilhvitfeldt.github.io/ISLR-tidymodels-labs/03-linear-regression.html\n\n# tidy model way\n\n specs <- linear_reg() %>%\n  set_mode(\"regression\") %>%\n  set_engine(\"lm\")\n\nlm_3 <- specs %>%\n  fit(sold~ lag1 + lag2 + rolling_4wk_avg , data = is_train)\n\nlm_4 <- specs %>%\n  fit(sold~ month + lag1 + lag2 + rolling_4wk_avg , data = is_train)\n\nlm_5 <- specs %>%\n  fit(sold~ month + week + lag1 + lag2 + rolling_4wk_avg , data = is_train)\n\n\nmod_compare <-  rbind(glance(lm_3),glance(lm_4),glance(lm_5))\nmod_compare\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 12\n  r.squared adj.r.squared sigma statistic p.value    df   logLik     AIC     BIC\n      <dbl>         <dbl> <dbl>     <dbl>   <dbl> <dbl>    <dbl>   <dbl>   <dbl>\n1     0.597         0.597  133.     9213.       0     3 -117797. 235603. 235642.\n2     0.597         0.597  133.     6910.       0     4 -117796. 235605. 235652.\n3     0.597         0.597  133.     5528.       0     5 -117796. 235606. 235661.\n# ℹ 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n```\n:::\n:::\n\n\ninterpret the results\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbind_cols(\n  predict(lm_3, new_data = is_train, type = \"conf_int\"),\n  is_train\n) %>%\n  select(item_no, week, sold, .pred_lower, .pred_upper)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 19,764 × 5\n   item_no  week  sold .pred_lower .pred_upper\n   <chr>   <dbl> <int>       <dbl>       <dbl>\n 1 020-502     0     0       NA          NA   \n 2 020-502     1     0       NA          NA   \n 3 020-502     2     0       NA          NA   \n 4 020-502     3     0       -1.93        2.19\n 5 020-502     4    84       40.3        44.4 \n 6 020-502     5     0       -1.48        2.69\n 7 020-502     6     0       -2.59        1.58\n 8 020-502     7    84       82.5        86.7 \n 9 020-502     8     0       -1.48        2.69\n10 020-502     9     0       -2.59        1.58\n# ℹ 19,754 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlm_3 <- specs %>%\n  fit(sold~ lag1 + lag2 + rolling_4wk_avg , data = is_train)\n\nlm_3t <- specs %>%\n  fit(sold~ lag1 + lag2 + rolling_4wk_avg , data = is_test)\n\ntt_compare <-  rbind(glance(lm_3),glance(lm_3t))\ntt_compare$mod <-  c(\"train\", \"test\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nactual_predicted <- bind_cols(\n  predict(lm_3t, new_data = is_train, type = \"conf_int\"),\n  is_train\n) %>%\n  select(item_no, week, sold, .pred_lower, .pred_upper)\n```\n:::\n\n\n\n# graph results\n\n\n\n",
    "supporting": [
      "pi_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
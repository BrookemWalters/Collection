{
  "hash": "9bc1890ad4eca89f5cea004a14f2c8ed",
  "result": {
    "markdown": "---\ntitle: \"inventory prediction\"\nformat: \n  html:\n    code-fold: true\n---\n\n\n\n\nDRAFT DRAFT OUTLINE\n\n# Project Overview\n\n**goal**: predict inventory for the following year\n\n**limitations**: 12 months of data is not great for this preserves the temporal order. A more robust data set to work on would include a couple years of data\n\n**steps:**\n\n-   exploratory analysis and descriptive analytics -\n-   feature engineer new variables -\n-   step-wise model selection\n-   test and train a predictive model\n-   interpret and evaluate the results\n-   visualize the process\n\n## Initial Insights:\n\nThe initial inventory data set contains 488 items sold over the course of 54 weeks (0-53)\n\nThe figures below distribution of items sold by item type and week. The line graph shows the seasonality of the product\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist <- sai %>% \n  group_by(item_no) %>%\n  summarise(total_sold = sum(sold)) %>% \n \nggplot(aes(x = total_sold)) +\n  geom_histogram(binwidth = 2100, color = \"black\", fill = \"#7D998F\", \n                 alpha = .6) +\n        scale_x_continuous(labels = scales::comma_format()) +\n  \n  labs(x = \"Number of Items Sold\", y = \"Count of Item Type\", \n       title = \"Number of Items Sold by Item Type\", \n       caption =  \" figure a\")+\n    theme_art_nouveau()\n\n\n\nhist1 <- sai %>% \n  group_by(week) %>%\n  summarise(total_sold = sum(sold)) %>% \n \nggplot(aes(x = total_sold)) +\n  geom_histogram(binwidth =  2100, color = \"black\", fill = \"#DF5875\", \n                 alpha = .6) +\n        scale_x_continuous(labels = scales::comma_format()) +\n        scale_y_continuous(position = \"right\") +\n  \n  labs(x = \"Number of Items Sold\", y = \"Count of Weeks\", \n       title = \"Number of Items Sold by Week\",\n        caption =  \" figure b\")+\n  theme_art_nouveau()\n\n# display the histograms side by side\ngridExtra::grid.arrange(hist, hist1, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](pi_files/figure-html/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n-   What does this histogram tell me?\n    -   sales per week is slightly more evenly distributed throughout the sales cycle\n    -   the average week sells \\~25K\n\n\n::: {.cell}\n\n```{.r .cell-code}\nline1 <- sai %>%\n  group_by(week) %>%\n  summarise(total_sold = sum(sold)) %>%\n  ggplot(aes(x = week, y = total_sold)) +\n  geom_line(size = 2, alpha = 0.5, color = \"#DF5875\") +\n  geom_point(size = 4, alpha = 0.5, color = \"#DF5875\")+\n  geom_area(fill = \"#DF5875\", alpha = 0.4) +\n  scale_x_continuous(breaks = seq(0, 55, by = 5)) + \n  scale_y_continuous(labels = scales::comma_format()) +\n   \n  labs(x = \"week\", y = \"Count of Items Sold\", \n       title = \"Number of Items Sold by Week\",\n        caption =  \" figure c\")+\n  theme_art_nouveau()\nline1\n```\n\n::: {.cell-output-display}\n![](pi_files/figure-html/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n## Feature engineering\n\nI needed to create a few more variables help with the predictions:\n\n(link to data dictionary)\n\n-   totals for each item over the year\n-   which items are best selling? top ten items based on volume\n-   convert weeks to dates so we can extract the month\n-   lag period for seasonality\n-   rolling mean\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# total yearly sales for each item\ninventory_sum <- sai %>%\n  group_by(item_no) %>%\n  summarise(year_total = sum(sold), .groups = \"drop\")\n\nsai <- left_join(sai, inventory_sum, by = c(\"item_no\"))\n\n###\n# calculate the top 10% threshold\ntop_10_threshold <- quantile(sai$year_total, 0.9)\n\n# dummy variable for bestsellers 1= yes 0 = no\nsai <- sai %>%\n  mutate(best_seller = ifelse(year_total >= top_10_threshold, 1, 0))\n\n## figure out month an year for data, assuming the data is from  2022\n# week 0: December 27, 2021 - January 2, 2022\n# week 52: December 19, 2022 - December 25, 2022\n# week 53: December 26, 2022 - January 1, 2023\n\nsai$year <- 2022\n\nsai <- sai %>%\n  mutate(calendar_week = ifelse(week == 0, 52, ifelse(week == 53, 1, week)),\n         calendar_year = ifelse(week == 0, year - 1, ifelse(week == 53, year + 1, year)))\n\n# Now use calendar_year and calendar_week in the MMWRweek2Date function\nsai$date <- MMWRweek2Date(sai$calendar_year, sai$calendar_week)\n\n\n\n# find the year the week ends in, so we can figure out months\nsai <- sai %>%\n  mutate(wk_ending_year = ifelse(week %in% c(0, 53), year + 1, year),\n         week = ifelse(week == 53, 1, week))\n\n\n\n# create teh data and extract the month\n# wanted month to be quantitative to reduce model complexity\n\nsai$date <- MMWRweek2Date(sai$wk_ending_year, sai$calendar_week)\nsai$month <- month(sai$date, label = TRUE)\nsai$month <- month(sai$date)\n\n\n# create lag periods\n# https://www.youtube.com/watch?v=Kn3llTjYS5E\n\nsai <- sai %>%\n  mutate(lag1 = lag(sold, 1),\n         lag2 = lag(sold, 2))\n\n# https://www.rdocumentation.org/packages/zoo/versions/1.8-12/topics/rollmean\nsai <- sai %>%\n  group_by(item_no) %>%\n  mutate(rolling_4wk_avg = zoo::rollmean(sold, k = 4, fill = NA, align = \"right\")) %>%\n  ungroup()\n\nwrite.csv(sai, \"FEinventory.csv\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmonth_abbreviations <- c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\")\n\nsai_average <-  sai %>%\n  filter(wk_ending_year == 2022) %>% \n  group_by(month) %>% \n  summarise(month_average = mean(sold))\n\n\n\nbar <- sai %>%\n    filter(wk_ending_year == 2022) %>% \n    mutate(month = factor(month, levels = 1:12, labels = month_abbreviations)) %>%\n  ggplot(aes(x = month, y = sold)) +\n  geom_bar(stat = \"sum\", fill = \"#68576D\", alpha = 0.75) +\n  labs(x = \"Month\", y = \"Total Sold\", title = \"Total Sold by Month\",\n       caption =  \" figure d\") +\n  theme_art_nouveau() +\n  theme(legend.position = \"none\")\n\ndot <-  sai_average %>%\n  mutate(month = factor(month, levels = 1:12, labels = month_abbreviations)) %>%\n  ggplot(aes(x=month, y= month_average)) +\n  geom_point(size = 4, shape = 8, alpha = .75)+\n  scale_y_continuous(position = \"right\") +\n  labs(x = \"Month\", y = \"Average Sold\", title = \"Average Items Sold by Month\",\n       caption =  \" figure e\") +\n  theme_art_nouveau() \n \n  \n\ngridExtra::grid.arrange(bar, dot, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](pi_files/figure-html/unnamed-chunk-5-1.png){width=960}\n:::\n:::\n\n\n### splitting the data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create a list of all items to randomly select\nset.seed(1985)\nitems_sample_list <-  unique(sai$item_no) %>% \n  sample(366)\n# 75% of the data\n\n\n# splitting the inventory by item type to keep the temporal order\n\nis_train <-  sai %>% \n  filter(item_no %in% items_sample_list) %>% \n  dplyr::select(\n    item_no,\n    week,\n    month,\n    lag1,\n    lag2,\n    rolling_4wk_avg,\n    best_seller, \n    sold) #not sure why i had to include the dplyr package\n\n\nis_test<-  sai %>% \n  filter(!(item_no %in% items_sample_list)) %>% \n  dplyr::select(\n    item_no,\n    week,\n    month,\n    lag1,\n    lag2,\n    rolling_4wk_avg,\n    best_seller, \n    sold) #not sure why i had to include the dplyr package\n```\n:::\n\n\ncreate a model based on the best selling item, inventory with more items sold are more predictable.\n\n## Model Selection\n\nfind the best model using stepwise selection find the 2 best methods for every size predictors reasons to use stepwise with caution - reason a - reason b - reason c\n\n-   define generalized linear regression and why I chose this for the model\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# https://youtu.be/IScjygOnO0w\n# forward Stepwise Selection\n# nvmax = 8 specifies the maximum number of predictors to incorporate in the model.\nis_mod <- regsubsets(sold ~ week + month + lag1 + lag2 + rolling_4wk_avg + best_seller,\n                       data = is_test, nbest = 2, method = \"exhaustive\")\nis_mod_summary_mx <- with(summary(is_mod), data.frame(rsq,adjr2, cp, rss, outmat))\n\nis_mod_summary_mx$predictors <- c(1,1,2,2,3,3,4,4,5,5,6) # for graphing\nis_mod_summary_mx$model <- c('a','b','a','b','a','b','a','b','a', 'b', 'a') # for graphing\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# turn results into a pretty table\n# is_mod_summary_mx\n```\n:::\n\n\n### model evaluation\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# make this chart prettier\ncustom_colors <- c(\"#68576D\", \"#DF5875\")\n\nis_mod_summary_mx %>%\n  pivot_longer(c(adjr2, cp), names_to = \"metric\", values_to = \"value\") %>%\n  ggplot(aes(x = predictors, y = value, color = model)) +\n  geom_line(show.legend = FALSE) +\n  geom_point() +\n  facet_wrap(~metric, scales = \"free\") +\n  scale_x_continuous(breaks = 1:6) +\n  scale_color_manual(values = custom_colors) +  # Set custom colors here\n  theme_art_nouveau()\n```\n\n::: {.cell-output-display}\n![](pi_files/figure-html/unnamed-chunk-9-1.png){width=960}\n:::\n:::\n\n\n\\[interpret the graph\\]\n\nexplain why this is the best one what do each of these things tell me? - rsq -\\> highest r squared, explains the variability in the model - adjr2 - \\> highest - cp -\\> smallest - rss -\\> smallest\n\nhaving trouble choosing, i spent a lot of time making my variables so lets look at AIC several models what is AIC? Lower AIC values indicate a better-fit model, and a model with a delta-AIC (the difference between the two AIC values being compared) of more than -2 is considered significantly better than the model it is being compared to\n\nfind the coefficients and (Akaike Information Criterion) AIC Multiple linear regression compare the three best models\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#https://emilhvitfeldt.github.io/ISLR-tidymodels-labs/03-linear-regression.html\n\n# tidy model way\n\n specs <- linear_reg() %>%\n  set_mode(\"regression\") %>%\n  set_engine(\"lm\")\n\nlm_3 <- specs %>%\n  fit(sold~ lag1 + lag2 + rolling_4wk_avg , data = is_train)\n\nlm_4 <- specs %>%\n  fit(sold~ month + lag1 + lag2 + rolling_4wk_avg , data = is_train)\n\nlm_5 <- specs %>%\n  fit(sold~ month + week + lag1 + lag2 + rolling_4wk_avg , data = is_train)\n\n\nmod_compare <-  rbind(glance(lm_3),glance(lm_4),glance(lm_5))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# create a cool table\n# mod_compare\n```\n:::\n\n\ninterpret the results\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_precict <- bind_cols(\n  predict(lm_3, new_data = is_train, type = \"conf_int\"),\n  is_train\n) %>%\n  select(item_no, week, sold, .pred_lower, .pred_upper)\n\n# graph the results\n```\n:::\n\n\ncompare the train model against the test\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm_3 <- specs %>%\n  fit(sold~ lag1 + lag2 + rolling_4wk_avg , data = is_train)\n\nlm_3t <- specs %>%\n  fit(sold~ lag1 + lag2 + rolling_4wk_avg , data = is_test)\n\ntt_compare <-  rbind(glance(lm_3),glance(lm_3t))\ntt_compare$mod <-  c(\"train\", \"test\")\n\n# create a visualization\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nactual_predicted <- bind_cols(\n  predict(lm_3t, new_data = is_train, type = \"conf_int\"),\n  is_train\n) %>%\n  select(item_no, week, sold, .pred_lower, .pred_upper)\n```\n:::\n\n\n### graph results\n",
    "supporting": [
      "pi_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}